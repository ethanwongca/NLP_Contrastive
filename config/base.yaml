data_cfg:
  stage: "fit"
  batch_size: 3
  max_length: 128
  num_workers: 0 
  fps: 2
  train_shards: "{00000..00031}.tar"
  val_shards: "{00000..00001}.tar"
  test_shards: "{00000..00002}.tar"
  data_dir: /scratch/st-jzhu71-1/ewong25/my_jupyter/How2Sign_web
  processor_model_path: /scratch/st-jzhu71-1/ldm0612/models/Qwen2.5-VL-3B-Instruct

model_cfg:
  class_path: encoders.experiment.VideoTextExp
  init_args:
    text_encoder_cfg:
      pretrained_model_path: /scratch/st-jzhu71-1/ldm0612/models/jina-embeddings-v3
      xlm_roberta_flash_implementation_path: /scratch/st-jzhu71-1/ldm0612/models/xlm-roberta-flash-implementation
      task: text-matching
      out_hidden_size: 1024  # The matryoshka dimension

    video_encoder_cfg:
      pretrained_model_path: /scratch/st-jzhu71-1/ldm0612/models/Qwen2.5-VL-3B-Instruct
      depth: 32
      fullatt_block_indexes: [7, 15, 23, 31]
      hidden_act: silu
      hidden_size: 1024  
      in_channels: 3
      intermediate_size: 4096
      model_type: qwen2_5_vl
      num_heads: 16
      out_hidden_size: 1024
      patch_size: 14
      spatial_merge_size: 2
      temporal_patch_size: 2
      tokens_per_second: 4
      transformers_version: 4.49.0
      window_size: 112
      _attn_implementation: eager
      proj_size: 512
      torch_dtype: bfloat16
      seq_len: 341
      video_token_id: 151656

    optimizer_cfg:
      initial_lr: 0.0001
      weight_decay: 0.001
      num_warmup_steps: 0

    loss_cfg:
      # rank: 0
      world_size: 1
      loss_dist_impl: gather

    eval_cfg:
      eval_model_path: /scratch/st-jzhu71-1/ldm0612/models/all-MiniLM-L6-v2

